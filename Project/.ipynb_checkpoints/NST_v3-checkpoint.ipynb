{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb70e4a-cfba-4b3e-8549-a957e3bc2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_image(image_path):\n",
    "    max_dim = 512\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def show_image(image, title=None):\n",
    "    if len(image.shape) > 3:\n",
    "        image = tf.squeeze(image, axis=0)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def save_image(image, filename):\n",
    "  \"\"\"Saves the image to a file with the given filename.\"\"\"\n",
    "  image = image.numpy()\n",
    "  image = np.array(image * 255, dtype=np.uint8)  # Convert to uint8 for PIL\n",
    "  image = Image.fromarray(image)\n",
    "  image.save(filename)\n",
    "\n",
    "def get_model():\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "    content_layers = ['block5_conv2']\n",
    "    outputs = [vgg.get_layer(name).output for name in style_layers + content_layers]\n",
    "    return tf.keras.Model(inputs=vgg.input, outputs=outputs)\n",
    "\n",
    "def gram_matrix(input_tensor):\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    a = tf.reshape(input_tensor, [-1, channels])\n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "    return gram / tf.cast(tf.shape(a)[0], tf.float32)\n",
    "\n",
    "def total_variation_loss(image):\n",
    "    return tf.reduce_sum(tf.image.total_variation(image))\n",
    "\n",
    "def compute_loss(outputs, content_targets, style_targets, target_image, style_weight, content_weight, tv_weight):\n",
    "    style_outputs = outputs[:len(style_targets)]\n",
    "    content_outputs = outputs[len(style_targets):]\n",
    "    style_score = sum(style_weight * tf.reduce_mean((gram_matrix(style_output) - target)**2) for style_output, target in zip(style_outputs, style_targets))\n",
    "    content_score = sum(content_weight * tf.reduce_mean((content_output - target)**2) for content_output, target in zip(content_outputs, content_targets))\n",
    "    tv_loss = total_variation_loss(target_image)\n",
    "    return style_score + content_score + tv_weight * tv_loss\n",
    "\n",
    "def run_style_transfer(content_path, style_path, num_iterations, style_weight, content_weight, tv_weight):\n",
    "    model = get_model()\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.02, beta_1=0.99, epsilon=0.1)\n",
    "    target_image = tf.Variable(load_image(content_path))\n",
    "    content_image = load_image(content_path)\n",
    "    style_image = load_image(style_path)\n",
    "    style_features = model(style_image)\n",
    "    content_features = model(content_image)\n",
    "    style_targets = [gram_matrix(feature) for feature in style_features]\n",
    "    content_targets = [feature for feature in content_features]\n",
    "    for i in range(num_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(target_image)\n",
    "            loss = compute_loss(outputs, content_targets, style_targets, target_image, style_weight, content_weight, tv_weight)\n",
    "        grad = tape.gradient(loss, target_image)\n",
    "        optimizer.apply_gradients([(grad, target_image)])\n",
    "        target_image.assign(tf.clip_by_value(target_image, 0.0, 1.0))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration: {i}, Loss: {loss.numpy()}, Style Weight: {style_weight}, Content Weight: {content_weight}\")\n",
    "            show_image(target_image.read_value())\n",
    "    show_image(target_image.read_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a32fa3-a9fe-4b08-9994-778d57c2d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_style_transfer('content04.jpg', 'style05.jpg', num_iterations=1000, style_weight=0.01, content_weight=100000, tv_weight=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
